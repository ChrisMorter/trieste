{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2ac072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 17:26:06.460636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:06.460655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-11-10 17:26:07.500279: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-10 17:26:07.523492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 17:26:07.524013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\n",
      "2021-11-10 17:26:07.524075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-11-10 17:26:07.524347: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-10 17:26:07.524704: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-10 17:26:07.525046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-10 17:26:07.525058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lunar_lander\n",
    "from turbo_test import demo_heuristic_lander\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import trieste\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a64fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this space is created by going approximately +-0.2 around parameter values, but not going below 0\n",
    "# see for original values https://github.com/openai/gym/blob/master/gym/envs/box2d/lunar_lander.py\n",
    "# original values are\n",
    "# 0.5 1 0.4 0.55 0.5 1 0.5 0.5 0 0.5 0.05 0.05\n",
    "# and for parameter definition https://github.com/uber-research/TuRBO\n",
    "search_space = trieste.space.Box(\n",
    "    [0.3, 0.8, 0.2, 0.35, 0.3, 0.8, 0.3, 0.3, 0.0, 0.3, 0.0,  0.0],\n",
    "    [0.7, 1.2, 0.6, 0.75, 0.7, 1.2, 0.7, 0.7, 0.2, 0.7, 0.25, 0.25]\n",
    ")\n",
    "\n",
    "# lander landed, minimize fuel\n",
    "FUEL = \"FUEL\"\n",
    "# minimize failures, when the lander crashes or times out\n",
    "FAILURE = \"FAILURE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f2af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_empty_dataset = lambda : trieste.data.Dataset(\n",
    "                                    tf.zeros((0, search_space.dimension), tf.float64),\n",
    "                                    tf.zeros((0, 1), tf.float64)\n",
    "                                )\n",
    "\n",
    "def lander_observer(x):\n",
    "    all_datasets = {\n",
    "        FUEL: create_empty_dataset(),\n",
    "        FAILURE: create_empty_dataset()\n",
    "    }\n",
    "\n",
    "    def add_data(dataset_tag, x, y):\n",
    "        new_dataset = trieste.data.Dataset(np.atleast_2d(x), np.atleast_2d(y))\n",
    "        all_datasets[dataset_tag] += new_dataset\n",
    "\n",
    "    for w in x.numpy():\n",
    "        result = demo_heuristic_lander(lunar_lander.LunarLander(), w)\n",
    "        # that's different from constrained optimization\n",
    "        # because now we want to minimize failure\n",
    "        # and not penalize by it\n",
    "        # thus we flip the 1 and 0 values in this dataset\n",
    "        if result.timeout or result.has_crashed:\n",
    "            add_data(FAILURE, w, 1.0)\n",
    "            continue\n",
    "        else:\n",
    "            add_data(FAILURE, w, 0.0)\n",
    "\n",
    "        normalized_fuel = np.float64(result.total_fuel / 100.0)\n",
    "        add_data(FUEL, w, normalized_fuel)\n",
    "    \n",
    "    return all_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83939974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DemoHeuristicResult: reward: 276.35, fuel: 20.49, steps: 203.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: -25.05, fuel: 7.26, steps: 69.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: 26.19, fuel: 15.42, steps: 111.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: 0.04, fuel: 14.13, steps: 102.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: -218.36, fuel: 20.31, steps: 110.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -74.25, fuel: 10.62, steps: 77.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 262.24, fuel: 44.97, steps: 288.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 230.05, fuel: 46.89, steps: 438.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: -92.49, fuel: 14.55, steps: 100.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 273.00, fuel: 21.36, steps: 204.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 267.31, fuel: 37.29, steps: 294.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 17.02, fuel: 14.10, steps: 103.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 58.81, fuel: 12.00, steps: 91.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: -188.39, fuel: 37.44, steps: 239.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 33.45, fuel: 12.60, steps: 105.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: -12.34, fuel: 44.88, steps: 250.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -147.19, fuel: 18.09, steps: 109.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 33.30, fuel: 23.79, steps: 160.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: 4.99, fuel: 21.18, steps: 135.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: 50.39, fuel: 13.38, steps: 74.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: -31.86, fuel: 8.52, steps: 69.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 22.39, fuel: 11.76, steps: 102.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: 159.19, fuel: 29.19, steps: 1001.0, crashed: False, timeout: True, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -42.00, fuel: 9.93, steps: 91.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: -103.24, fuel: 42.27, steps: 251.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -83.15, fuel: 15.00, steps: 138.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -12.31, fuel: 10.53, steps: 77.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -12.39, fuel: 12.99, steps: 96.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: -19.00, fuel: 12.75, steps: 77.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 247.68, fuel: 26.37, steps: 197.0, crashed: False, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 234.79, fuel: 25.77, steps: 320.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 11.80, fuel: 12.21, steps: 90.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 265.43, fuel: 34.26, steps: 254.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 37.67, fuel: 14.16, steps: 82.0, crashed: True, timeout: False, is_in_helipad: True, success: False\n",
      "DemoHeuristicResult: reward: 284.50, fuel: 22.20, steps: 184.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: -50.09, fuel: 11.82, steps: 94.0, crashed: True, timeout: False, is_in_helipad: False, success: False\n",
      "DemoHeuristicResult: reward: 281.82, fuel: 45.12, steps: 445.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 253.35, fuel: 28.71, steps: 255.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "DemoHeuristicResult: reward: 237.52, fuel: 16.53, steps: 205.0, crashed: False, timeout: False, is_in_helipad: True, success: True\n",
      "12\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "num_initial_points = 1\n",
    "initial_query_points = search_space.sample(1)\n",
    "initial_data = lander_observer(initial_query_points)\n",
    "\n",
    "# collect points until we have at least one in each dataset\n",
    "while any(len(initial_data[tag]) < search_space.dimension for tag in initial_data):\n",
    "    initial_query_points = search_space.sample(1)\n",
    "    new_initial_data = lander_observer(initial_query_points)\n",
    "    for tag in initial_data:\n",
    "        initial_data[tag] = initial_data[tag] + new_initial_data[tag]\n",
    "    num_initial_points += 1\n",
    "\n",
    "\n",
    "print(len(initial_data[FUEL]))\n",
    "print(len(initial_data[FAILURE]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8178176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "\n",
    "\n",
    "def create_regression_model(data):\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.Matern52(variance, lengthscales=[0.2]*int(search_space.dimension))\n",
    "    scale = tf.constant(1.0, dtype=tf.float64)\n",
    "    kernel.variance.prior = tfp.distributions.LogNormal(\n",
    "        tf.constant(-2.0, dtype=tf.float64), scale\n",
    "    )\n",
    "    kernel.lengthscales.prior = tfp.distributions.LogNormal(\n",
    "        tf.math.log(kernel.lengthscales), scale\n",
    "    )\n",
    "    gpr = gpflow.models.GPR(data.astuple(), kernel)\n",
    "    return gpr\n",
    "\n",
    "\n",
    "def create_classification_model(data):\n",
    "    kernel = gpflow.kernels.SquaredExponential(\n",
    "        lengthscales=[0.2]*int(search_space.dimension)\n",
    "    )\n",
    "    likelihood = gpflow.likelihoods.Bernoulli()\n",
    "    vgp = gpflow.models.VGP(data.astuple(), kernel, likelihood)\n",
    "    return vgp\n",
    "\n",
    "from trieste.models.gpflow import GPflowModelConfig\n",
    "\n",
    "classification_model_config_args = {\n",
    "    \"model_args\": {\"use_natgrads\": True},\n",
    "    \"optimizer\": tf.optimizers.Adam(1e-3),\n",
    "    \"optimizer_args\": {\"max_iter\": 50},\n",
    "}\n",
    "models = {\n",
    "    FUEL: GPflowModelConfig(**{\n",
    "        \"model\": create_regression_model(initial_data[FUEL]),\n",
    "        \"optimizer\": gpflow.optimizers.Scipy(),\n",
    "    }),\n",
    "    FAILURE: GPflowModelConfig(\n",
    "        create_classification_model(initial_data[FAILURE]),\n",
    "        **classification_model_config_args\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b24aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialModelStack(trieste.models.ModelStack):\n",
    "    \"\"\" Special treatment of predict_joint used in sampler\n",
    "    \"\"\"\n",
    "    def __init__(self, models_dict):\n",
    "        super().__init__((models_dict[FUEL], 1), (models_dict[FAILURE], 1))\n",
    "        self._models_dict = models_dict\n",
    "\n",
    "    def predict(self, query_points):\n",
    "        fuel_mean, fuel_var = self._models_dict[FUEL].predict(query_points)\n",
    "        failure_mean, failure_var = self._models_dict[FAILURE].predict_y(query_points)\n",
    "        return tf.concat([fuel_mean, failure_mean], axis=-1), tf.concat([fuel_var, failure_var], axis=-1)\n",
    "\n",
    "\n",
    "class SpecialBatchMonteCarloExpectedHypervolumeImprovement(trieste.acquisition.function.AcquisitionFunctionBuilder):\n",
    "    \"\"\" The one in trieste is single model, and we need to pass two models and two datasets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_size: int, *, jitter: float = trieste.utils.misc.DEFAULTS.JITTER):\n",
    "        \"\"\"\n",
    "        :param sample_size: The number of samples from model predicted distribution for\n",
    "            each batch of points.\n",
    "        :param jitter: The size of the jitter to use when stabilising the Cholesky decomposition of\n",
    "            the covariance matrix.\n",
    "        :raise ValueError (or InvalidArgumentError): If ``sample_size`` is not positive, or\n",
    "            ``jitter`` is negative.\n",
    "        \"\"\"\n",
    "        tf.debugging.assert_positive(sample_size)\n",
    "        tf.debugging.assert_greater_equal(jitter, 0.0)\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self._sample_size = sample_size\n",
    "        self._jitter = jitter\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\"\"\"\n",
    "        return (\n",
    "            f\"SpecialBatchMonteCarloExpectedHypervolumeImprovement({self._sample_size!r},\"\n",
    "            f\" jitter={self._jitter!r})\"\n",
    "        )\n",
    "\n",
    "    def prepare_acquisition_function(\n",
    "        self,\n",
    "        models,\n",
    "        datasets,\n",
    "    ):\n",
    "        # failure dataset will have all points\n",
    "        # while fuel only successful ones\n",
    "        query_points = datasets[FAILURE].query_points\n",
    "        \n",
    "        # [0] is because we only need mean and not variance\n",
    "        means = tf.concat([models[FUEL].predict(query_points)[0], models[FAILURE].predict_y(query_points)[0]], axis=-1)\n",
    "        _pf = trieste.acquisition.multi_objective.pareto.Pareto(means)\n",
    "        _reference_pt = trieste.acquisition.multi_objective.pareto.get_reference_point(_pf.front)\n",
    "        # prepare the partitioned bounds of non-dominated region for calculating of the\n",
    "        # hypervolume improvement in this area\n",
    "        _partition_bounds = trieste.acquisition.multi_objective.partition.prepare_default_non_dominated_partition_bounds(_reference_pt, _pf.front)\n",
    "\n",
    "        sampler = trieste.acquisition.sampler.IndependentReparametrizationSampler(self._sample_size, SpecialModelStack(models))\n",
    "\n",
    "        return trieste.acquisition.function.batch_ehvi(sampler, self._jitter, _partition_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.acquisition.rule import EfficientGlobalOptimization\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "ITERATIONS = 250\n",
    "\n",
    "mc_ehvi = SpecialBatchMonteCarloExpectedHypervolumeImprovement(sample_size=5)\n",
    "rule = EfficientGlobalOptimization(mc_ehvi, num_query_points=BATCH_SIZE)\n",
    "\n",
    "\n",
    "bo = trieste.bayesian_optimizer.BayesianOptimizer(lander_observer, search_space)\n",
    "start = timeit.default_timer()\n",
    "result = bo.optimize(ITERATIONS, initial_data, models, rule).final_result.unwrap()\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c74934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fancy code to import trieste notebook plotting utils\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"plotting\", \"../docs/notebooks/util/plotting.py\")\n",
    "plotting = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_points = result.datasets[FAILURE].query_points\n",
    "objective_model_values, _ = result.models[FUEL].predict(all_query_points)\n",
    "failure_model_values, _ = result.models[FAILURE].predict_y(all_query_points)\n",
    "\n",
    "plt.scatter(objective_model_values, failure_model_values);\n",
    "plt.xlabel(\"Fuel spent, x0.01\");\n",
    "plt.ylabel(\"Probability of failure\");\n",
    "plt.show();\n",
    "\n",
    "points_in_objective_space = tf.concat([objective_model_values, failure_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points)\n",
    "plt.xlabel(\"Fuel spent, x0.01\");\n",
    "plt.ylabel(\"Probability of failure\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957023bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.models[FUEL]._model.kernel.lengthscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5250187",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.models[FAILURE]._model.kernel.lengthscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_failure(point, n_tries=100):\n",
    "    if not isinstance(point, np.ndarray):\n",
    "        point = point.numpy()\n",
    "\n",
    "    assert point.shape == (int(search_space.dimension),)\n",
    "\n",
    "    n_failures = 0\n",
    "    for _ in range(n_tries):\n",
    "        result = demo_heuristic_lander(lunar_lander.LunarLander(), point, print_result=False)\n",
    "        if result.timeout or result.has_crashed:\n",
    "            n_failures += 1\n",
    "    \n",
    "    return n_failures / n_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.acquisition.multi_objective.dominance import non_dominated\n",
    "\n",
    "pf_points, _ = non_dominated(tf.concat([objective_model_values, failure_model_values], axis=1))\n",
    "pf_input_points = []\n",
    "for pf_point in pf_points:\n",
    "    pf_input_point = tf.boolean_mask(all_query_points, tf.equal(objective_model_values, pf_point[0])[:,0])\n",
    "    if len(pf_input_point) > 1:\n",
    "        pf_input_point = pf_input_point[0:1, :]\n",
    "    pf_input_points.append(pf_input_point)\n",
    "pf_input_points = tf.concat(pf_input_points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_actual_values = [probability_of_failure(p) for p in pf_input_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e31236",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_objective_space = tf.concat([objective_model_values, failure_model_values], axis=1)\n",
    "\n",
    "mean, variance = result.models[FAILURE].predict(pf_input_points)\n",
    "failure_lower_conf_bounds, _ = result.models[FAILURE]._model.likelihood.predict_mean_and_var(\n",
    "    mean - 2 * tf.sqrt(variance), variance)\n",
    "failure_upper_conf_bounds, _ = result.models[FAILURE]._model.likelihood.predict_mean_and_var(\n",
    "    mean + 2 * tf.sqrt(variance), variance)\n",
    "\n",
    "mean, variance = result.models[FUEL].predict(pf_input_points)\n",
    "objective_lower_conf_bounds = mean - 2 * tf.sqrt(variance)\n",
    "objective_upper_conf_bounds = mean + 2 * tf.sqrt(variance)\n",
    "\n",
    "plotting.plot_mobo_points_in_obj_space(\n",
    "    points_in_objective_space,\n",
    "    num_init=num_initial_points,\n",
    "    only_plot_pareto=True,\n",
    "    figsize=(12,12)\n",
    ")\n",
    "plt.scatter(pf_points[:, 0], failure_actual_values, c='r')\n",
    "\n",
    "for i, (lower, upper) in enumerate(zip(failure_lower_conf_bounds, failure_upper_conf_bounds)):\n",
    "    plt.plot((pf_points[i].numpy()[0], pf_points[i].numpy()[0]), (lower,upper), '_-',color='orange')\n",
    "\n",
    "for i, (lower, upper) in enumerate(zip(objective_lower_conf_bounds, objective_upper_conf_bounds)):\n",
    "    plt.plot((lower,upper), (pf_points[i].numpy()[1], pf_points[i].numpy()[1]), '|-',color='green')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Fuel spent, x0.01\")\n",
    "plt.ylabel(\"Model probability of failure\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245bd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
