:py:mod:`trieste.acquisition.optimizer`
=======================================

.. py:module:: trieste.acquisition.optimizer

.. autoapi-nested-parse::

   This module contains functionality for optimizing
   :data:`~trieste.acquisition.AcquisitionFunction`\ s over :class:`~trieste.space.SearchSpace`\ s.



Module Contents
---------------

.. py:data:: SP
   

   Type variable bound to :class:`~trieste.space.SearchSpace`. 


.. py:data:: NUM_SAMPLES_MIN
   :annotation: :int = 5000

   The default minimum number of initial samples for :func:`generate_continuous_optimizer` and
   :func:`generate_random_search_optimizer` function, used for determining the number of initial
   samples in the multi-start acquisition function optimization.


.. py:data:: NUM_SAMPLES_DIM
   :annotation: :int = 1000

   The default minimum number of initial samples per dimension of the search space for
   :func:`generate_continuous_optimizer` function in :func:`automatic_optimizer_selector`, used for
   determining the number of initial samples in the multi-start acquisition function optimization.


.. py:exception:: FailedOptimizationError

   Bases: :py:obj:`Exception`

   Raised when an acquisition optimizer fails to optimize

   Initialize self.  See help(type(self)) for accurate signature.


.. py:data:: AcquisitionOptimizer
   

   Type alias for a function that returns the single point that maximizes an acquisition function over
   a search space. For a search space with points of shape [D], and acquisition function with input
   shape [..., B, D] output shape [..., 1], the :const:`AcquisitionOptimizer` return shape should be
   [B, D].


.. py:function:: automatic_optimizer_selector(space: trieste.space.SearchSpace, target_func: trieste.acquisition.interface.AcquisitionFunction) -> trieste.types.TensorType

   A wrapper around our :const:`AcquisitionOptimizer`s. This class performs
   an :const:`AcquisitionOptimizer` appropriate for the
   problem's :class:`~trieste.space.SearchSpace`.

   :param space: The space of points over which to search, for points with shape [D].
   :param target_func: The function to maximise, with input shape [..., 1, D] and output shape
           [..., 1].
   :return: The batch of points in ``space`` that maximises ``target_func``, with shape [1, D].


.. py:function:: optimize_discrete(space: trieste.space.DiscreteSearchSpace, target_func: trieste.acquisition.interface.AcquisitionFunction) -> trieste.types.TensorType

   An :const:`AcquisitionOptimizer` for :class:'DiscreteSearchSpace' spaces and
   batches of size of 1.

   :param space: The space of points over which to search, for points with shape [D].
   :param target_func: The function to maximise, with input shape [..., 1, D] and output shape
           [..., 1].
   :return: The **one** point in ``space`` that maximises ``target_func``, with shape [1, D].


.. py:function:: generate_continuous_optimizer(num_initial_samples: int = NUM_SAMPLES_MIN, num_optimization_runs: int = 1, num_recovery_runs: int = 5, optimizer_args: dict[str, Any] = dict()) -> AcquisitionOptimizer[Box | TaggedProductSearchSpace]

   Generate a gradient-based optimizer for :class:'Box' and :class:'TaggedProductSearchSpace'
   spaces and batches of size 1. In the case of a :class:'TaggedProductSearchSpace', We perform
   gradient-based optimization across all :class:'Box' subspaces, starting from the best location
   found across a sample of `num_initial_samples` random points.

   We advise the user to either use the default `NUM_SAMPLES_MIN` for `num_initial_samples`, or
   `NUM_SAMPLES_DIM` times the dimensionality of the search space, whichever is smaller.

   This optimizer supports Scipy's L-BFGS-B optimizer (used via GPflow's Scipy optimizer wrapper),
   which optimizes directly within and up to the bounds of the search space.

   For challenging acquisition function optimizations, we run `num_optimization_runs` separate
   optimizations, each starting from one of the top `num_optimization_runs` initial query points.

   If all `num_optimization_runs` optimizations fail to converge then we run up to
   `num_recovery_runs` starting from random locations.

   The default behavior of this method is to return a L-BFGS-B optimizer that performs
   a single optimization from the best of `NUM_SAMPLES_MIN` initial locations. If this
   optimization fails then we run up to `num_recovery_runs` recovery runs starting from additional
   random locations.

   :param num_initial_samples: The size of the random sample used to find the starting point(s) of
       the optimization.
   :param num_optimization_runs: The number of separate optimizations to run.
   :param num_recovery_runs: The maximum number of recovery optimization runs in case of failure.
   :param optimizer_args: The keyword arguments to pass to the GPflow's Scipy optimizer wrapper.
       Check `minimize` method  of :class:`~gpflow.optimizers.Scipy` for details what arguments
       can be passed.
   :return: The acquisition optimizer.


.. py:function:: get_bounds_of_box_relaxation_around_point(space: trieste.space.TaggedProductSearchSpace, current_point: trieste.types.TensorType) -> scipy.optimize.Bounds

   A function to return the bounds of a continuous relaxation of
   a :class:'TaggedProductSearchSpace' space, i.e. replacing discrete
   spaces with continuous spaces. In particular, all :class:'DiscreteSearchSpace'
   subspaces are replaced with a new :class:'DiscreteSearchSpace' fixed at their
   respective component of the specified 'current_point'. Note that
   all :class:'Box' subspaces remain the same.

   :param space: The original search space.
   :param current_point: The point at which to make the continuous relaxation.
   :return: Bounds for the Scipy optimizer.


.. py:function:: batchify(batch_size_one_optimizer: AcquisitionOptimizer[SP], batch_size: int) -> AcquisitionOptimizer[SP]

   A wrapper around our :const:`AcquisitionOptimizer`s. This class wraps a
   :const:`AcquisitionOptimizer` to allow it to optimize batch acquisition functions.

   :param batch_size_one_optimizer: An optimizer that returns only batch size one, i.e. produces a
           single point with shape [1, D].
   :param batch_size: The number of points in the batch.
   :return: An :const:`AcquisitionOptimizer` that will provide a batch of points with shape [B, D].


.. py:function:: generate_random_search_optimizer(num_samples: int = NUM_SAMPLES_MIN) -> AcquisitionOptimizer[SP]

   Generate an acquisition optimizer that samples `num_samples` random points across the space.
   The default is to sample at `NUM_SAMPLES_MIN` locations.

   We advise the user to either use the default `NUM_SAMPLES_MIN` for `num_samples`, or
   `NUM_SAMPLES_DIM` times the dimensionality of the search space, whichever is smaller.

   :param num_samples: The number of random points to sample.
   :return: The acquisition optimizer.


