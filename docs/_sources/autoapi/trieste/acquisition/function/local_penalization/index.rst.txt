:py:mod:`trieste.acquisition.function.local_penalization`
=========================================================

.. py:module:: trieste.acquisition.function.local_penalization

.. autoapi-nested-parse::

   This module contains local penalization-based acquisition function builders.



Module Contents
---------------

.. py:class:: LocalPenalizationAcquisitionFunction(search_space: trieste.space.SearchSpace, num_samples: int = 500, penalizer: Callable[[trieste.models.ProbabilisticModel, trieste.types.TensorType, trieste.types.TensorType, trieste.types.TensorType], Union[trieste.acquisition.interface.PenalizationFunction, trieste.acquisition.interface.UpdatablePenalizationFunction]] = None, base_acquisition_function_builder: ExpectedImprovement | MinValueEntropySearch | None = None)

   Bases: :py:obj:`trieste.acquisition.interface.SingleModelGreedyAcquisitionBuilder`

   Builder of the acquisition function maker for greedily collecting batches by local
   penalization.  The resulting :const:`AcquisitionFunctionMaker` takes in a set of pending
   points and returns a base acquisition function penalized around those points.
   An estimate of the objective function's Lipschitz constant is used to control the size
   of penalization.

   Local penalization allows us to perform batch Bayesian optimization with a standard (non-batch)
   acquisition function. All that we require is that the acquisition function takes strictly
   positive values. By iteratively building a batch of points though sequentially maximizing
   this acquisition function but down-weighted around locations close to the already
   chosen (pending) points, local penalization provides diverse batches of candidate points.

   Local penalization is applied to the acquisition function multiplicatively. However, to
   improve numerical stability, we perform additive penalization in a log space.

   The Lipschitz constant and additional penalization parameters are estimated once
   when first preparing the acquisition function with no pending points. These estimates
   are reused for all subsequent function calls.

   :param search_space: The global search space over which the optimisation is defined.
   :param num_samples: Size of the random sample over which the Lipschitz constant
       is estimated. We recommend scaling this with search space dimension.
   :param penalizer: The chosen penalization method (defaults to soft penalization). This
       should be a function that accepts a model, pending points, lipschitz constant and eta
       and returns a PenalizationFunction.
   :param base_acquisition_function_builder: Base acquisition function to be
       penalized (defaults to expected improvement). Local penalization only supports
       strictly positive acquisition functions.
   :raise tf.errors.InvalidArgumentError: If ``num_samples`` is not positive.

   .. py:method:: prepare_acquisition_function(self, model: trieste.models.ProbabilisticModel, dataset: Optional[trieste.data.Dataset] = None, pending_points: Optional[trieste.types.TensorType] = None) -> trieste.acquisition.interface.AcquisitionFunction

      :param model: The model.
      :param dataset: The data from the observer. Must be populated.
      :param pending_points: The points we penalize with respect to.
      :return: The (log) expected improvement penalized with respect to the pending points.
      :raise tf.errors.InvalidArgumentError: If the ``dataset`` is empty.


   .. py:method:: update_acquisition_function(self, function: trieste.acquisition.interface.AcquisitionFunction, model: trieste.models.ProbabilisticModel, dataset: Optional[trieste.data.Dataset] = None, pending_points: Optional[trieste.types.TensorType] = None, new_optimization_step: bool = True) -> trieste.acquisition.interface.AcquisitionFunction

      :param function: The acquisition function to update.
      :param model: The model.
      :param dataset: The data from the observer. Must be populated.
      :param pending_points: Points already chosen to be in the current batch (of shape [M,D]),
          where M is the number of pending points and D is the search space dimension.
      :param new_optimization_step: Indicates whether this call to update_acquisition_function
          is to start of a new optimization step, of to continue collecting batch of points
          for the current step. Defaults to ``True``.
      :return: The updated acquisition function.



.. py:class:: local_penalizer(model: trieste.models.ProbabilisticModel, pending_points: trieste.types.TensorType, lipschitz_constant: trieste.types.TensorType, eta: trieste.types.TensorType)

   Bases: :py:obj:`trieste.acquisition.interface.UpdatablePenalizationFunction`

   An :class:`UpdatablePenalizationFunction` builds and updates a penalization function.
   Defining a penalization function that can be updated avoids having to retrace on every call.

   Initialize the local penalizer.

   :param model: The model over the specified ``dataset``.
   :param pending_points: The points we penalize with respect to.
   :param lipschitz_constant: The estimated Lipschitz constant of the objective function.
   :param eta: The estimated global minima.
   :return: The local penalization function. This function will raise
       :exc:`ValueError` or :exc:`~tf.errors.InvalidArgumentError` if used with a batch size
       greater than one.

   .. py:method:: update(self, pending_points: trieste.types.TensorType, lipschitz_constant: trieste.types.TensorType, eta: trieste.types.TensorType) -> None

      Update the local penalizer with new variable values.



.. py:class:: soft_local_penalizer(model: trieste.models.ProbabilisticModel, pending_points: trieste.types.TensorType, lipschitz_constant: trieste.types.TensorType, eta: trieste.types.TensorType)

   Bases: :py:obj:`local_penalizer`

   Return the soft local penalization function used for single-objective greedy batch Bayesian
   optimization in :cite:`Gonzalez:2016`.

   Soft penalization returns the probability that a candidate point does not belong
   in the exclusion zones of the pending points. For model posterior mean :math:`\mu`, model
   posterior variance :math:`\sigma^2`, current "best" function value :math:`\eta`, and an
   estimated Lipschitz constant :math:`L`,the penalization from a set of pending point
   :math:`x'` on a candidate point :math:`x` is given by
   .. math:: \phi(x, x') = \frac{1}{2}\textrm{erfc}(-z)
   where :math:`z = \frac{1}{\sqrt{2\sigma^2(x')}}(L||x'-x|| + \eta - \mu(x'))`.

   The penalization from a set of pending points is just product of the individual
   penalizations. See :cite:`Gonzalez:2016` for a full derivation.

   :param model: The model over the specified ``dataset``.
   :param pending_points: The points we penalize with respect to.
   :param lipschitz_constant: The estimated Lipschitz constant of the objective function.
   :param eta: The estimated global minima.
   :return: The local penalization function. This function will raise
       :exc:`ValueError` or :exc:`~tf.errors.InvalidArgumentError` if used with a batch size
       greater than one.

   Initialize the local penalizer.

   :param model: The model over the specified ``dataset``.
   :param pending_points: The points we penalize with respect to.
   :param lipschitz_constant: The estimated Lipschitz constant of the objective function.
   :param eta: The estimated global minima.
   :return: The local penalization function. This function will raise
       :exc:`ValueError` or :exc:`~tf.errors.InvalidArgumentError` if used with a batch size
       greater than one.

   .. py:method:: __call__(self, x: trieste.types.TensorType) -> trieste.types.TensorType

      Call penalization function..



.. py:class:: hard_local_penalizer(model: trieste.models.ProbabilisticModel, pending_points: trieste.types.TensorType, lipschitz_constant: trieste.types.TensorType, eta: trieste.types.TensorType)

   Bases: :py:obj:`local_penalizer`

   Return the hard local penalization function used for single-objective greedy batch Bayesian
   optimization in :cite:`Alvi:2019`.

   Hard penalization is a stronger penalizer than soft penalization and is sometimes more effective
   See :cite:`Alvi:2019` for details. Our implementation follows theirs, with the penalization from
   a set of pending points being the product of the individual penalizations.

   :param model: The model over the specified ``dataset``.
   :param pending_points: The points we penalize with respect to.
   :param lipschitz_constant: The estimated Lipschitz constant of the objective function.
   :param eta: The estimated global minima.
   :return: The local penalization function. This function will raise
       :exc:`ValueError` or :exc:`~tf.errors.InvalidArgumentError` if used with a batch size
       greater than one.

   Initialize the local penalizer.

   :param model: The model over the specified ``dataset``.
   :param pending_points: The points we penalize with respect to.
   :param lipschitz_constant: The estimated Lipschitz constant of the objective function.
   :param eta: The estimated global minima.
   :return: The local penalization function. This function will raise
       :exc:`ValueError` or :exc:`~tf.errors.InvalidArgumentError` if used with a batch size
       greater than one.

   .. py:method:: __call__(self, x: trieste.types.TensorType) -> trieste.types.TensorType

      Call penalization function..



